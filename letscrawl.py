import requests
from bs4 import BeautifulSoup
import json
import time
from typing import List, Dict, Optional


class CompanyCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.headers = {
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
            "Referer": "https://icis.me.go.kr/pageLink.do",
            "Origin": "https://icis.me.go.kr",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "X-Requested-With": "XMLHttpRequest"
        }
    
    def search_companies_by_material(self, material_name: str, year: str = "2022", max_companies: int = 10) -> List[Dict]:
        """ë¬¼ì§ˆëª…ìœ¼ë¡œ ì—…ì²´ ëª©ë¡ ì¡°íšŒ"""
        print(f"ğŸ” ë¬¼ì§ˆëª… '{material_name}'ìœ¼ë¡œ {year}ë…„ë„ ì—…ì²´ ê²€ìƒ‰ ì¤‘...")
        
        list_url = "https://icis.me.go.kr/iprtr/cdrInfoDetailListJson.do"
        list_data = {
            "search1": year,
            "search3": "",
            "search4": "",
            "search5": "ì „ì²´ì§€ì—­",
            "search6": "",
            "search7": "ì „ì²´ì§€ì—­",
            "mttrGroup": "",
            "searchCategory": "03",
            "searchMttrWord": material_name,
            "irsttList": "",
            "level": "",
            "indutyCode": "",
            "indutyCode2": "",
            "indutyCode3": "",
            "indutyCode4": "",
            "pageNo": "1"
        }
        
        try:
            response = self.session.post(list_url, headers=self.headers, data=list_data)
            response.raise_for_status()
            results = response.json()
            
            companies = results.get("list", [])[:max_companies]
            print(f"âœ… {len(companies)}ê°œ ì—…ì²´ ë°œê²¬")
            return companies
            
        except Exception as e:
            print(f"âŒ ì—…ì²´ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_company_details(self, bplc_id: str, year: str = "2022") -> Dict:
        """ì—…ì²´ IDë¡œ ìƒì„¸ì •ë³´ ì¡°íšŒ"""
        print(f"ğŸ“‹ ì—…ì²´ ID '{bplc_id}' ìƒì„¸ì •ë³´ ì¡°íšŒ ì¤‘...")
        
        detail_url = 'https://icis.me.go.kr/iprtr/cdrInfoView.do'
        detail_headers = {
            'Content-Type': 'application/x-www-form-urlencoded',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'https://icis.me.go.kr/pageLink.do'
        }
        
        detail_data = {
            'bplcId': bplc_id,
            'streNo': '',
            'searchYear': year,
        }
        
        try:
            response = self.session.post(detail_url, headers=detail_headers, data=detail_data)
            response.encoding = response.apparent_encoding
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ê¸°ë³¸ ì •ë³´ í…Œì´ë¸” ì°¾ê¸°
            basic_table = soup.find('table', class_='view_table')
            if not basic_table:
                basic_table = soup.find('table', class_='viewTypeA')
            if not basic_table:
                basic_table = soup.find('table', class_='tbl_st3')
            
            result = {"bplcId": bplc_id}
            
            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            if basic_table:
                tbody = basic_table.find('tbody')
                rows = tbody.find_all('tr') if tbody else basic_table.find_all('tr')
                
                # í•„ë“œ ì¶”ì¶œ í•¨ìˆ˜
                def extract_field(field_name):
                    for row in rows:
                        th_list = row.find_all('th')
                        td_list = row.find_all('td')
                        for th, td in zip(th_list, td_list):
                            if field_name in th.text.strip():
                                return td.text.strip()
                    return None
                
                # ê¸°ë³¸ í•„ë“œ ë¦¬ìŠ¤íŠ¸
                fields = [
                    'ì—…ì²´ëª…', 'ëŒ€í‘œì', 'ì†Œì¬ì§€', 'ëŒ€í‘œì—…ì¢…',
                    'ì¢…ì—…ì›ìˆ˜', 'ê´€í•  í™˜ê²½ì²­', 'ì‚¬ì—…ì¥ ë¹„ìƒì—°ë½ë²ˆí˜¸',
                    'ì„¤ë¦½ë…„ë„', 'ìë³¸ê¸ˆ', 'ë§¤ì¶œì•¡', 'ì—…ì¢…ë¶„ë¥˜'
                ]
                
                for field in fields:
                    value = extract_field(field)
                    if value:
                        result[field] = value
            
            # ì—…ì²´ëª…ì´ ì—†ìœ¼ë©´ ì œëª©ì—ì„œ ì¶”ì¶œ ì‹œë„
            if 'ì—…ì²´ëª…' not in result or not result['ì—…ì²´ëª…']:
                company_name = soup.select_one("td.title strong")
                if company_name:
                    result['ì—…ì²´ëª…'] = company_name.text.strip()
            
            # í™”í•™ë¬¼ì§ˆ ì •ë³´ í…Œì´ë¸” ì°¾ê¸° ë° ì¶”ì¶œ
            chemical_tables = soup.find_all('table')
            chemical_data = []
            
            for table in chemical_tables:
                # í—¤ë”ì—ì„œ CAS No., ì—°ê°„ì…ê³ ëŸ‰, ì—°ê°„ì‚¬ìš©íŒë§¤ëŸ‰ì´ ìˆëŠ” í…Œì´ë¸” ì°¾ê¸°
                thead = table.find('thead')
                if not thead:
                    continue
                    
                header_text = thead.get_text()
                if 'CAS No' in header_text and ('ì…ê³ ' in header_text or 'ì‚¬ìš©' in header_text):
                    tbody = table.find('tbody')
                    if not tbody:
                        continue
                    
                    # í—¤ë” êµ¬ì¡° ë¶„ì„
                    header_rows = thead.find_all('tr')
                    column_mapping = {}
                    
                    for header_row in header_rows:
                        cells = header_row.find_all(['th', 'td'])
                        col_index = 0
                        
                        for cell in cells:
                            cell_text = cell.get_text(strip=True).replace('\n', ' ').replace('\r', ' ')
                            colspan = int(cell.get('colspan', 1))
                            
                            if 'CAS No' in cell_text or 'CAS' in cell_text:
                                column_mapping['cas_no'] = col_index
                            elif 'ì…ê³ ' in cell_text and 'ì—°ê°„' in cell_text:
                                column_mapping['annual_input'] = col_index
                            elif 'ì‚¬ìš©' in cell_text and 'íŒë§¤' in cell_text and 'ì—°ê°„' in cell_text:
                                column_mapping['annual_usage'] = col_index
                            elif 'ë¬¼ì§ˆëª…' in cell_text or 'ë¬¼ì§ˆëª…ì¹­' in cell_text:
                                column_mapping['material_name'] = col_index
                            
                            col_index += colspan
                    
                    # ë°ì´í„° í–‰ ì¶”ì¶œ
                    data_rows = tbody.find_all('tr')
                    for row in data_rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) > max(column_mapping.values()) if column_mapping else False:
                            chemical_info = {}
                            
                            # ê° ì»¬ëŸ¼ ë°ì´í„° ì¶”ì¶œ
                            if 'material_name' in column_mapping:
                                chemical_info['ë¬¼ì§ˆëª…'] = cells[column_mapping['material_name']].get_text(strip=True)
                            
                            if 'cas_no' in column_mapping:
                                chemical_info['CAS_No'] = cells[column_mapping['cas_no']].get_text(strip=True)
                            
                            if 'annual_input' in column_mapping:
                                chemical_info['ì—°ê°„ì…ê³ ëŸ‰'] = cells[column_mapping['annual_input']].get_text(strip=True)
                            
                            if 'annual_usage' in column_mapping:
                                chemical_info['ì—°ê°„ì‚¬ìš©íŒë§¤ëŸ‰'] = cells[column_mapping['annual_usage']].get_text(strip=True)
                            
                            # ë¹ˆ ë°ì´í„°ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                            if any(chemical_info.values()):
                                chemical_data.append(chemical_info)
            
            # í™”í•™ë¬¼ì§ˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
            if chemical_data:
                result['í™”í•™ë¬¼ì§ˆì •ë³´'] = chemical_data
                print(f"âœ… ì—…ì²´ '{result.get('ì—…ì²´ëª…', bplc_id)}' ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ (í™”í•™ë¬¼ì§ˆ {len(chemical_data)}ê°œ)")
            else:
                print(f"âœ… ì—…ì²´ '{result.get('ì—…ì²´ëª…', bplc_id)}' ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            print(f"âŒ ì—…ì²´ ID '{bplc_id}' ìƒì„¸ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"bplcId": bplc_id, "error": str(e)}
    
    def crawl_companies_by_material(self, material_name: str, year: str = "2022", 
                                  max_companies: int = 10, delay: float = 1.0) -> List[Dict]:
        """ë¬¼ì§ˆëª…ìœ¼ë¡œ ì—…ì²´ ê²€ìƒ‰ í›„ ëª¨ë“  ì—…ì²´ì˜ ìƒì„¸ì •ë³´ ìˆ˜ì§‘"""
        print(f"ğŸš€ ë¬¼ì§ˆëª… '{material_name}' ê¸°ë°˜ ì—…ì²´ì •ë³´ í¬ë¡¤ë§ ì‹œì‘")
        print(f"ğŸ“… ê²€ìƒ‰ë…„ë„: {year}, ìµœëŒ€ ì—…ì²´ìˆ˜: {max_companies}, ìš”ì²­ê°„ê²©: {delay}ì´ˆ")
        print("-" * 60)
        
        # 1. ì—…ì²´ ëª©ë¡ ì¡°íšŒ
        companies = self.search_companies_by_material(material_name, year, max_companies)
        if not companies:
            return []
        
        # 2. ê° ì—…ì²´ ìƒì„¸ì •ë³´ ìˆ˜ì§‘
        all_details = []
        for i, company in enumerate(companies, 1):
            bplc_id = company.get("bplcId")
            if not bplc_id:
                continue
                
            print(f"[{i}/{len(companies)}] ", end="")
            detail_info = self.get_company_details(bplc_id, year)
            
            # ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ë„ í¬í•¨
            detail_info.update({
                "ê²€ìƒ‰_ìˆœë²ˆ": i,
                "ì›ë³¸_ì—…ì²´ëª…": company.get("bplcNm", ""),
                "ì›ë³¸_ì†Œì¬ì§€": company.get("addr", ""),
            })
            
            all_details.append(detail_info)
            
            # ìš”ì²­ ê°„ê²© ì¡°ì ˆ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            if i < len(companies):
                time.sleep(delay)
        
        print("-" * 60)
        print(f"ğŸ‰ ì´ {len(all_details)}ê°œ ì—…ì²´ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!")
        return all_details
    
    def save_to_json(self, data: List[Dict], filename: str = None) -> str:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            filename = f"ì—…ì²´ì •ë³´_{int(time.time())}.json"
        
        try:
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    crawler = CompanyCrawler()
    
    # ì‚¬ìš©ì ì…ë ¥
    material_name = input("ğŸ” ì¡°íšŒí•  ë¬¼ì§ˆëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 7727-21-1): ").strip()
    if not material_name:
        print("âŒ ë¬¼ì§ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    year = input("ğŸ“… ê²€ìƒ‰í•  ì—°ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 2022): ").strip() or "2022"
    
    try:
        max_companies = int(input("ğŸ“Š ìµœëŒ€ ì¡°íšŒí•  ì—…ì²´ ìˆ˜ (ê¸°ë³¸ê°’: 10): ").strip() or "10")
    except ValueError:
        max_companies = 10
    
    try:
        delay = float(input("â±ï¸  ìš”ì²­ ê°„ê²©(ì´ˆ, ê¸°ë³¸ê°’: 1.0): ").strip() or "1.0")
    except ValueError:
        delay = 1.0
    
    print("\n" + "="*60)
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    results = crawler.crawl_companies_by_material(
        material_name=material_name,
        year=year,
        max_companies=max_companies,
        delay=delay
    )
    
    if results:
        # ê²°ê³¼ ì €ì¥
        filename = f"{material_name}_{year}ë…„_ì—…ì²´ì •ë³´.json"
        crawler.save_to_json(results, filename)
        
        # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
        print("\nğŸ“ˆ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì´ ì—…ì²´ ìˆ˜: {len(results)}")
        successful = len([r for r in results if 'error' not in r])
        print(f"   - ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ì—…ì²´: {successful}")
        if successful < len(results):
            print(f"   - ìˆ˜ì§‘ ì‹¤íŒ¨ ì—…ì²´: {len(results) - successful}")
        
        # í™”í•™ë¬¼ì§ˆ ì •ë³´ í†µê³„
        total_chemicals = sum(len(r.get('í™”í•™ë¬¼ì§ˆì •ë³´', [])) for r in results)
        companies_with_chemicals = len([r for r in results if r.get('í™”í•™ë¬¼ì§ˆì •ë³´')])
        if total_chemicals > 0:
            print(f"   - í™”í•™ë¬¼ì§ˆ ì •ë³´ê°€ ìˆëŠ” ì—…ì²´: {companies_with_chemicals}")
            print(f"   - ì´ í™”í•™ë¬¼ì§ˆ ë°ì´í„°: {total_chemicals}ê°œ")
        
        # ìƒìœ„ 3ê°œ ì—…ì²´ëª… ì¶œë ¥
        print("\nğŸ“‹ ìˆ˜ì§‘ëœ ì£¼ìš” ì—…ì²´:")
        for i, result in enumerate(results[:3], 1):
            company_name = result.get('ì—…ì²´ëª…', result.get('ì›ë³¸_ì—…ì²´ëª…', f"ì—…ì²´ID_{result.get('bplcId')}"))
            chemical_count = len(result.get('í™”í•™ë¬¼ì§ˆì •ë³´', []))
            chemical_info = f" (í™”í•™ë¬¼ì§ˆ {chemical_count}ê°œ)" if chemical_count > 0 else ""
            print(f"   {i}. {company_name}{chemical_info}")
        
        if len(results) > 3:
            print(f"   ... ì™¸ {len(results)-3}ê°œ ì—…ì²´")
    
    else:
        print("âŒ ìˆ˜ì§‘ëœ ì—…ì²´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()